{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A:\n",
      "[[ 2  4  1  3]\n",
      " [ 5  0 -2  3]\n",
      " [ 0 -1 -3  4]\n",
      " [ 1  1  2  2]]\n",
      "b: [1 2 3 4]\n",
      "--------------------------------------------------------------\n",
      "Theoretical Solution for X:\n",
      " [ 0.05405405 -1.08108108  1.16216216  1.35135135]\n"
     ]
    }
   ],
   "source": [
    "# part 1: Theoretical Part:\n",
    "import numpy as np\n",
    "\n",
    "A = np.array([[2,4,1,3],\n",
    "              [5,0,-2,3],\n",
    "              [0,-1,-3,4],\n",
    "              [1,1,2,5]])\n",
    "b = np.array([1,2,3,4])\n",
    "\n",
    "print(\"A-inverse:\", np.linalg.inv(A))\n",
    "\n",
    "# x_theoretical = np.linalg.inv(A.T @ A) @ (A.T @ b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value of X after 100 iterations is:\n",
      " [ 0.02011036 -0.34084217  0.4050907   0.92041009]\n",
      "The value of X after 200 iterations is:\n",
      " [ 0.01272439 -0.64357435  0.71966108  1.11566054]\n",
      "The value of X after 300 iterations is:\n",
      " [ 0.02741522 -0.82507846  0.90381785  1.21563631]\n",
      "The value of X after 400 iterations is:\n",
      " [ 0.03821147 -0.93158398  1.01136537  1.27235452]\n",
      "The value of X after 500 iterations is:\n",
      " [ 0.04477274 -0.99381473  1.07414506  1.30526827]\n",
      "The value of X after 600 iterations is:\n",
      " [ 0.04863277 -1.03014495  1.11078875  1.32445682]\n",
      "The value of X after 700 iterations is:\n",
      " [ 0.05088932 -1.05135086  1.13217682  1.33565405]\n",
      "The value of X after 800 iterations is:\n",
      " [ 0.05220683 -1.06372831  1.1446605   1.34218929]\n",
      "The value of X after 900 iterations is:\n",
      " [ 0.05297587 -1.07095272  1.15194689  1.3460037 ]\n",
      "The value of X after 1000 iterations is:\n",
      " [ 0.05342474 -1.07516942  1.15619978  1.34823006]\n",
      "--------------------------------------------------------------\n",
      "Estimated X using the Gradient Descent:\n",
      " [ 0.05342474 -1.07516942  1.15619978  1.34823006]\n"
     ]
    }
   ],
   "source": [
    "# part 2: Gradient Descent:\n",
    "import numpy as np\n",
    "\n",
    "# Example A and b (replace with your own)\n",
    "A = np.array([[1, 2],\n",
    "              [3, 4],\n",
    "              [5, 6]])\n",
    "b = np.array([1, 0, 1])\n",
    "\n",
    "# Gradient descent parameters\n",
    "alpha = 0.001     # learning rate\n",
    "iterations = 1000\n",
    "\n",
    "# Initialize x (zeros)\n",
    "x = np.zeros(A.shape[1])\n",
    "\n",
    "for i in range(iterations):\n",
    "    # Compute gradient: ∇f(x) = 2 A^T (A x - b)\n",
    "    grad = 2 * A.T.dot(A.dot(x) - b)\n",
    "\n",
    "    # Update rule x = x - α ∇f(x)\n",
    "    x = x - alpha * grad\n",
    "\n",
    "# Final result\n",
    "print(\"Estimated x:\", x)\n",
    "\n",
    "# Compare with theoretical least-squares solution\n",
    "x_theoretical = np.linalg.inv(A.T @ A) @ (A.T @ b)\n",
    "print(\"Theoretical x:\", x_theoretical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "tf_env",
   "language": "python",
   "display_name": "Python (tf_env)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
